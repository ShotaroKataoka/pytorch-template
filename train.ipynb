{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define hyper-params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model param\n",
    "model_name = \"model01\"\n",
    "\n",
    "# train param\n",
    "epochs = 100\n",
    "batch_size = 1\n",
    "optimizer_name = [\"Adam\", \"SGD\"][0]\n",
    "lr = 1e-3\n",
    "weight_decay = 1e-10\n",
    "\n",
    "# other settings\n",
    "import torch\n",
    "cuda = True and torch.cuda.is_available()\n",
    "gpu_ids = (0)\n",
    "\n",
    "\n",
    "print(\"[Model param]\")\n",
    "print(\"model_name:\", model_name)\n",
    "print()\n",
    "print(\"[Train param]\")\n",
    "print(\"epochs:\", epochs)\n",
    "print(\"batch_size:\", batch_size)\n",
    "print(\"optimizer_name:\", optimizer_name)\n",
    "print(\"lr:\", lr)\n",
    "print(\"weight_decay:\", weight_decay)\n",
    "print()\n",
    "print(\"[Other setting]\")\n",
    "print(\"cuda:\", cuda)\n",
    "print(\"gpu_ids:\", gpu_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataloader.dataset import Dataset\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Make datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = Dataset(\"train\")\n",
    "valset = Dataset(\"val\")\n",
    "testset = Dataset(\"test\")\n",
    "num_class = trainset.NUM_CLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    plt.subplot(1,4,i+1)\n",
    "    im = trainset[i][\"input\"].numpy()\n",
    "    im = im.transpose(1,2,0)\n",
    "    plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loop = {\"train\": trainset, \"val\": valset, \"test\": testset}\n",
    "i=0\n",
    "for split, sets in loop.items():\n",
    "    i += 1\n",
    "    print(split,\":\")\n",
    "    labels = {}\n",
    "    try:\n",
    "        for data in sets:\n",
    "            label = data[\"label\"].item()\n",
    "            try:\n",
    "                labels[label] += 1\n",
    "            except:\n",
    "                labels[label] = 1\n",
    "    except:\n",
    "        print(\"None\")\n",
    "        continue\n",
    "                \n",
    "    for key in labels.keys():\n",
    "        print(\"label [{}] is {}.\".format(key, labels[key]))\n",
    "    plt.subplot(1,3,i)\n",
    "    plt.subplots_adjust(wspace=0.4)\n",
    "    plt.bar(range(len(labels)), labels.values())\n",
    "    plt.title(split)\n",
    "    plt.xticks(range(len(labels)), labels.keys())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(valset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Define Saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.saver import Saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = Saver(model_name, lr, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.save_experiment_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Tensorboard Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.summaries import TensorboardSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = TensorboardSummary(saver.experiment_dir)\n",
    "writer = summary.create_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from modeling.modeling import Modeling\n",
    "from config import Config\n",
    "conf = Config()\n",
    "\n",
    "cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Modeling(embedding_dim=conf.embedding_dim,\n",
    "                 c_out=conf.num_class,\n",
    "                 c_hidden=conf.hidden_channel,\n",
    "                 cuda=cuda,\n",
    "                 hidden_layer=conf.hidden_layer)\n",
    "word_vector = gensim.models.KeyedVectors.load_word2vec_format(conf.word_vector_dir+'model.vec', binary=False)\n",
    "model.word_embeddings.weight = nn.Parameter(torch.from_numpy(word_vector.vectors))\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "model.word_embeddings.weight.requires_grad=False\n",
    "if cuda:\n",
    "    model = torch.nn.DataParallel(model, device_ids=(0,))\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"./run/model01/experiment_06/checkpoint.pth.tar\"\n",
    "model_state = torch.load(PATH)\n",
    "state_dict = model_state[\"state_dict\"]\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(num_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if optimizer_name==\"Adam\":\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "elif optimizer_name==\"SGD\":\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(reduction=\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from config import pycolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(epoch, best_pred, mode=\"train\"):\n",
    "    # ------------------------- #\n",
    "    # Initializing\n",
    "    epoch_loss = 0.0\n",
    "    ## Set model mode & tqdm (progress bar; it wrap dataloader)\n",
    "    assert mode==\"train\" or mode==\"val\", \"argument 'mode' can be 'train' or 'val.' Not {}.\".format(mode)\n",
    "    if mode==\"train\":\n",
    "        print(pycolor.GREEN + \"[Epoch: {}]\".format(epoch) + pycolor.END)\n",
    "        print(pycolor.YELLOW+\"Training:\"+pycolor.END)\n",
    "        model.train()\n",
    "        tbar = tqdm(train_loader, leave=False)\n",
    "        num_dataset = len(train_loader)\n",
    "    elif mode==\"val\":\n",
    "        print(pycolor.YELLOW+\"Validation:\"+pycolor.END)\n",
    "        model.eval()\n",
    "        tbar = tqdm(val_loader, leave=False)\n",
    "        num_dataset = len(val_loader)\n",
    "    ## Reset confusion matrix of evaluator\n",
    "    evaluator.reset()\n",
    "\n",
    "    # ------------------------- #\n",
    "    # Run 1 epoch\n",
    "    for i, sample in enumerate(tbar):\n",
    "        inputs, target = sample[\"input\"], sample[\"label\"]\n",
    "        if cuda:\n",
    "            inputs, target = inputs.cuda(), target.cuda()\n",
    "        if mode==\"train\":\n",
    "            optimizer.zero_grad()\n",
    "            output = model(inputs)\n",
    "        elif mode==\"val\":\n",
    "            with torch.no_grad():\n",
    "                output = model(inputs)\n",
    "        loss = criterion(output, target).sum()\n",
    "        if mode==\"train\":\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        tbar.set_description('{} loss: {:.3f}'.format(mode, (epoch_loss / ((i + 1)*batch_size))))\n",
    "        # Compute Metrics\n",
    "        pred = output.data.cpu().numpy()\n",
    "        pred = np.argmax(pred, axis=1)\n",
    "        target = target.cpu().numpy()\n",
    "        ## Add batch into evaluator\n",
    "        evaluator.add_batch(target, pred)\n",
    "\n",
    "    # ------------------------- #\n",
    "    # Save Log\n",
    "    ## **********Evaluate**********\n",
    "    Acc = evaluator.Accuracy()\n",
    "    F_score_Average = evaluator.F_score_Average()\n",
    "\n",
    "    ## Save results\n",
    "    writer.add_scalar('{}/loss_epoch'.format(mode), epoch_loss / num_dataset, epoch)\n",
    "    writer.add_scalar('{}/Acc'.format(mode), Acc, epoch)\n",
    "    writer.add_scalar('{}/F_score'.format(mode), F_score_Average, epoch)\n",
    "    print('Total {} loss: {:.3f}'.format(mode, epoch_loss / num_dataset))\n",
    "    print(\"Acc:{}, F_score:{}\".format(Acc, F_score_Average))\n",
    "\n",
    "    ## Save model\n",
    "    if mode==\"val\":\n",
    "        new_pred = F_score_Average\n",
    "        print(\"---------------------\")\n",
    "        if new_pred > best_pred:\n",
    "            is_best = True\n",
    "            print(\"model improve best score from {:.4f} to {:.4f}.\".format(best_pred, new_pred))\n",
    "            best_pred = new_pred\n",
    "            saver.save_checkpoint({\n",
    "                'epoch': epoch + 1,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'best_pred': best_pred,\n",
    "            }, is_best)\n",
    "    return best_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all():\n",
    "    best_pred = 0\n",
    "    for epoch in tqdm(range(epochs), desc=\"Epochs:\"):\n",
    "        ## ***Train***\n",
    "        run_epoch(epoch, best_pred, mode=\"train\")\n",
    "        ## ***Validation***\n",
    "        best_pred = run_epoch(epoch, best_pred, mode=\"val\")\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "run_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
